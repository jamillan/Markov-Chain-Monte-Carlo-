{
 "metadata": {
  "name": "",
  "signature": "sha256:8ff6553ec3e2a77a64dc884494319b3b7bb1a18c42dc7960d10c9e0b71a47286"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import os\n",
      "import json\n",
      "from numpy import linalg as LA"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.book import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "*** Introductory Examples for the NLTK Book ***\n",
        "Loading text1, ..., text9 and sent1, ..., sent9\n",
        "Type the name of the text or sentence to view it.\n",
        "Type: 'texts()' or 'sents()' to list the materials.\n",
        "text1:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Moby Dick by Herman Melville 1851\n",
        "text2:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Sense and Sensibility by Jane Austen 1811\n",
        "text3:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " The Book of Genesis\n",
        "text4:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Inaugural Address Corpus\n",
        "text5:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Chat Corpus\n",
        "text6:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Monty Python and the Holy Grail\n",
        "text7:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Wall Street Journal\n",
        "text8:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Personals Corpus\n",
        "text9:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " The Man Who Was Thursday by G . K . Chesterton 1908\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Let's Look int Moby Dick !!!!!\n",
      "#We want to find probability from going from a long word to a short word in text (and viceversa)\n",
      "#text1 is Moby Dick\n",
      "len(text1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "260819"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Import mc module\n",
      "import mc\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get the size of each word (token) throughout whole book\n",
      "freq_sizes = [len(w) for w in text1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Initial transitional matrix\n",
      "# State 0 = Short Word\n",
      "# State 1 = Long Word\n",
      "\n",
      "A = np.zeros([2,2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#number of charaters in short word (tokens)\n",
      "short =7"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A = np.zeros([2,2])\n",
      "short = 9\n",
      "\n",
      "#Calculate the transition matrix\n",
      "#Loop word by word and by reading the adjacent word get \n",
      "# the probability to jump from short word to long word, short word to short word ....\n",
      "\n",
      "#short and long words counters \n",
      "nbr_shortwords = []\n",
      "nbr_longwords = []\n",
      "\n",
      "#Use 200 words\n",
      "for i in range(200):\n",
      "    #size of word i\n",
      "    word = freq_sizes[i]\n",
      "    #size of adjacent word i+1\n",
      "    n_word = freq_sizes[i+1]\n",
      "\n",
      "    #if word i is short\n",
      "    if word < short:\n",
      "        nbr_shortwords.append(word)\n",
      "        node_0 =0\n",
      "        if n_word < short:\n",
      "            #adjacent word is short\n",
      "            node_1 = 0\n",
      "            A[node_0,node_1] += 1\n",
      "        \n",
      "        else:\n",
      "            #adjacent word is long\n",
      "            node_1 = 1\n",
      "            A[node_0 , node_1] += 1\n",
      "            \n",
      "    #if word i is long\n",
      "    else:\n",
      "        nbr_longwords.append(word)\n",
      "        node_0 = 1\n",
      "        if n_word < short:\n",
      "            #adjacent word is short\n",
      "            node_1 = 0\n",
      "            A[node_0,node_1]+=1\n",
      "            \n",
      "        else:\n",
      "            #adjacent word is long\n",
      "            node_1 = 1\n",
      "            A[node_0 , node_1] += 1\n",
      "            \n",
      "print A"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 177.   11.]\n",
        " [  11.    1.]]\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#normalized transition matrix\n",
      "norm_row1 = A[0][0] + A[0][1]\n",
      "norm_row2 = A[1][0]  + A[1][1]\n",
      "\n",
      "A[0][0] = A[0][0] / norm_row1\n",
      "A[0][1] = A[0][1] / norm_row1\n",
      "A[1][0] = A[1][0] / norm_row2\n",
      "A[1][1] = A[1][1] / norm_row2\n",
      "print \"Transition Matrix :\"\n",
      "print A\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Transition Matrix :\n",
        "[[ 0.94148936  0.05851064]\n",
        " [ 0.91666667  0.08333333]]\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Use Markovian Chains to find equilibrium transition\n",
      "\n",
      "dir = os.getcwd()\n",
      "params = json.load(open(dir + '/params.json' , 'r'))\n",
      "totalsteps = params[\"totalsteps\"]\n",
      "seed =  params[\"seed\"]\n",
      "skipsteps = params[\"skipsteps\"]\n",
      "node_0  = params[\"initnode\"]\n",
      "node_1  = params[\"finalnode\"]\n",
      "\n",
      "mobydick = mc.MC(dir + '/randwalk.dat', seed[0] , totalsteps ,node_0[0] , node_1[0], 10*skipsteps)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Pass Transition matrix as calculated above\n",
      "mobydick.adjmatrix(A)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#raise transition matrix to 10 power : columns show distribution equilibrium if share same values\n",
      "B=mobydick.raisematrix(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print B\n",
      "longword_mean_size = np.mean(nbr_longwords)\n",
      "shortword_mean_size = np.mean(nbr_shortwords)\n",
      "long_word_std_size = np.std(nbr_longwords)\n",
      "short_word_std_size = np.std(nbr_shortwords)\n",
      "print \"size of long words : \", longword_mean_size , \"std of long words : \", long_word_std_size \n",
      "print \"size of short words : \" , shortword_mean_size , \"std of long words : \",short_word_std_size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.94  0.06]\n",
        " [ 0.94  0.06]]\n",
        "size of long words :  10.25 std of long words :  1.29903810568\n",
        "size of short words :  3.31382978723 std of long words :  1.97925953615\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# use simulation to validate results \n",
      "dist_short_word =mobydick.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ETS |  34952533333.3 \t| steps remaining :  0 / 500000 \t| time remaining :  1.43051147461e-05 seconds\n",
        "ETS | "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 484942.774194 \t| steps remaining :  100000 / 500000 \t| time remaining :  0.82483959198 seconds\n",
        "ETS | "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 251968.564484 \t| steps remaining :  200000 / 500000 \t| time remaining :  1.1906247139 seconds\n",
        "ETS | "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 169587.286646 \t| steps remaining :  300000 / 500000 \t| time remaining :  1.17933368683 seconds\n",
        "ETS | "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 528845.324585 \t| steps remaining :  400000 / 500000 \t| time remaining :  0.189091205597 seconds\n",
        "****Simulation Complete****"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"distribution of short word via Matrix multiplication simulation,respectively \",B[0][0],dist_short_word"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "distribution of short word via Matrix multiplication simulation,respectively  0.94 0.939794\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# do the same for the long words\n",
      "mobydick = mc.MC(dir +'/randwalk.dat', seed[0] , totalsteps ,node_0[0] , node_1[1], 10*skipsteps)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Pass Transition matrix as calculated above\n",
      "mobydick.adjmatrix(A)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#use simulation to validate results \n",
      "dist_long_word =mobydick.run()\n",
      "\n",
      "print \"*****distribution of long word via Matrix and multiplication simulation, respectively \",B[0][1],dist_long_word"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ETS |  32263876923.1 \t| steps remaining :  0 / 500000 \t| time remaining :  1.54972076416e-05 seconds\n",
        "ETS | "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 412319.94259 \t| steps remaining :  100000 / 500000 \t| time remaining :  0.970120429993 seconds\n",
        "ETS | "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 474829.197275 \t| steps remaining :  200000 / 500000 \t| time remaining :  0.631806135178 seconds\n",
        "ETS | "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 512875.243641 \t| steps remaining :  300000 / 500000 \t| time remaining :  0.389958381653 seconds\n",
        "ETS | "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 258564.178943 \t| steps remaining :  400000 / 500000 \t| time remaining :  0.386751174927 seconds\n",
        "****Simulation Complete****"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "*****distribution of long word via Matrix multiplication simulation, respectively  0.06 0.060206\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "#Let's Look into Wall Street Journal (text7 from nltk)\n",
      "#get the size of each word throughout whole text\n",
      "freq_sizes = [len(w) for w in text7]\n",
      "A = np.zeros([2,2])\n",
      "#size of short words\n",
      "short = 9\n",
      "\n",
      "#Calculate the transition matrix\n",
      "#Loop word by word and by reading the adjacent word get \n",
      "# the probability to jump from short word to long word, short word to short word, ....\n",
      "\n",
      "#short and long words counters \n",
      "nbr_shortwords = []\n",
      "nbr_longwords = []\n",
      "for i in range(200):\n",
      "    #size of word i\n",
      "    word = freq_sizes[i]\n",
      "    #size of adjacent word i+1\n",
      "    n_word = freq_sizes[i+1]\n",
      "\n",
      "    #if word i is short\n",
      "    if word < short:\n",
      "        nbr_shortwords.append(word)\n",
      "        node_0 =0\n",
      "        if n_word < short:\n",
      "            #adjacent word is short\n",
      "            node_1 = 0\n",
      "            A[node_0,node_1] += 1\n",
      "        \n",
      "        else:\n",
      "            #adjacent word is long\n",
      "            node_1 = 1\n",
      "            A[node_0 , node_1] += 1\n",
      "            \n",
      "    #if word i is long\n",
      "    else:\n",
      "        nbr_longwords.append(word)\n",
      "        node_0 = 1\n",
      "        if n_word < short:\n",
      "            #adjacent word is short\n",
      "            node_1 = 0\n",
      "            A[node_0,node_1]+=1\n",
      "            \n",
      "        else:\n",
      "            #adjacent word is long\n",
      "            node_1 = 1\n",
      "            A[node_0 , node_1] += 1\n",
      "            \n",
      "print A\n",
      "\n",
      "longword_mean_size = np.mean(nbr_longwords)\n",
      "shortword_mean_size = np.mean(nbr_shortwords)\n",
      "long_word_std_size = np.std(nbr_longwords)\n",
      "short_word_std_size = np.std(nbr_shortwords)\n",
      "print \"size of long words : \", longword_mean_size , \"std of long words : \", long_word_std_size \n",
      "print \"size of short words : \" , shortword_mean_size , \"std of long words : \",short_word_std_size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 157.   20.]\n",
        " [  19.    4.]]\n",
        "size of long words :  10.1739130435 std of long words :  1.12876130311\n",
        "size of short words :  3.75706214689 std of long words :  2.17400366467\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#normalized transition matrix\n",
      "norm_row1 = A[0][0] + A[0][1]\n",
      "norm_row2 = A[1][0]  + A[1][1]\n",
      "print norm_row1\n",
      "print norm_row2\n",
      "A[0][0] = A[0][0] / norm_row1\n",
      "A[0][1] = A[0][1] / norm_row1\n",
      "A[1][0] = A[1][0] / norm_row2\n",
      "A[1][1] = A[1][1] / norm_row2\n",
      "print A"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "177.0\n",
        "23.0\n",
        "[[ 0.88700565  0.11299435]\n",
        " [ 0.82608696  0.17391304]]\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "init_node = 0\n",
      "dist_node = 1 \n",
      "m = mc.MC(dir + '/randwalk.dat', seed[0] , totalsteps ,0 , 1, 10*skipsteps)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m.adjmatrix(A)\n",
      "m.raisematrix(20)\n",
      "\n",
      "#*******Wall Street has a higher probability of Longer Words!!!!!!!!!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "array([[ 0.87967565,  0.12032435],\n",
        "       [ 0.87967565,  0.12032435]])"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    }
   ],
   "metadata": {}
  }
 ]
}